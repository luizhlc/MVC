{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9eb054c-342f-4ecb-b559-76eae8fcf010",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataset = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b88eacdf-ba24-4ee7-ba27-7350667c11ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import dataProcessing as dataP\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "np.random.seed(1222024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af1cd823-702b-4161-80d1-5e0ebdfe0f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(f\"./dataset/processed/\").mkdir(parents=True, exist_ok=True)\n",
    "classes_data = np.load('./dataset/raw/Classes.npy', allow_pickle=True)\n",
    "n_samples = len(classes_data)\n",
    "classes_k = ['Classe A','Classe B', 'Classe C','Classe D','Classe E']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444664e8-aeae-498b-bbeb-a922ceeb0c51",
   "metadata": {},
   "source": [
    "# Composição do dataset\n",
    "* treino: 70%, validação: 15%, teste: 15%\n",
    "* Como o dataset é balanceado, vou manter essa característica em cada um dos conjuntos\n",
    "    * Composição do dataset vai selecionar o mesmo número de elementos de cada classe para cada parte do dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cac3b43-a962-4cc2-a9a4-5edf7b8610f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_dist = [.7, .15, .15] #train, val, inference\n",
    "n_per_class = int(n_samples/len(classes_k))\n",
    "dataset_split_idxs = {}\n",
    "first_i = 0\n",
    "last_i = 0\n",
    "for label, d in zip(['train', 'val', 'test'], split_dist):\n",
    "    last_i = int(first_i+n_per_class*d)\n",
    "    dataset_split_idxs[label] = [first_i, last_i]\n",
    "    first_i = last_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6823e265-89c4-46d7-9f10-6dd66f1aa96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_idxs = {}\n",
    "for ck in classes_k:\n",
    "    class_idxs[ck] = np.where((classes_data==ck).flatten())[0]\n",
    "    np.random.shuffle(class_idxs[ck])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c2f3fe-1a3b-4c51-b477-453798fa10a0",
   "metadata": {},
   "source": [
    "# Coleta das features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83f10172-e691-40cf-9d7b-7c977b38a2b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_sensors = 3\n",
    "sensor_data = []\n",
    "for i in range(n_sensors):\n",
    "    sensor_data.append(np.load(f'./dataset/raw/Dados_{i+1}.npy', allow_pickle=True))\n",
    "    \n",
    "    for j in range(n_samples):\n",
    "        sensor_data[i][j] = dataP.fill_the_gaps(sensor_data[i][j])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac1ea178-1f78-4baf-af39-f28d1a6598a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 200\n",
    "freq = 10000\n",
    "time = 1/freq;\n",
    "rms_global = []\n",
    "peak = []\n",
    "peak2peak =[]\n",
    "crista = []\n",
    "fft_ys = []\n",
    "for s, s_data in enumerate(sensor_data):\n",
    "    # features\n",
    "    rms = dataP.get_RMS(s_data, freq, n, n)\n",
    "    rms_global.append(rms.flatten())\n",
    "    peak.append(dataP.get_peak(s_data))\n",
    "    crista.append(dataP.get_crista(peak[s], rms))\n",
    "    peak2peak.append(dataP.get_peak2peak(s_data))\n",
    "    # yfs\n",
    "    _, yfs = dataP.apply_fft(s_data, freq, n)\n",
    "    max_v = np.max(np.max(yfs))\n",
    "    fft_ys.append(yfs/max_v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3507485-51ca-4df9-987e-08426dcdf559",
   "metadata": {},
   "source": [
    "## Normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eebdc6e7-baa5-44f7-b782-a520ce411bc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_map = {\n",
    "    \"RMS\": rms_global, \n",
    "    \"Peak\": peak, \n",
    "    \"Peak2Peak\": peak2peak, \n",
    "    \"Crista\": crista\n",
    "}\n",
    "metrics_norm_map = {\n",
    "    \"RMS\": [], \n",
    "    \"Peak\": [], \n",
    "    \"Peak2Peak\": [], \n",
    "    \"Crista\": []\n",
    "}\n",
    "ft_limits = json.load(open('./norm_feat_params.json'))\n",
    "for m in metrics_map:\n",
    "    results = []\n",
    "    for s, s_data in enumerate(metrics_map[m]):\n",
    "        min_v, max_v = ft_limits[m][f's{s}']\n",
    "        result = (metrics_map[m][s]-min_v)/(max_v-min_v)\n",
    "        metrics_norm_map[m].append(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc1d0bf-d4df-4877-a627-deba495c78c2",
   "metadata": {},
   "source": [
    "# Separação das samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faba9d32-f45b-4b12-b322-8be24c1b3187",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schema={'Classe': 'string'}\n",
    "for s in range(n_sensors):\n",
    "    schema[f's{s}_RMS'] = 'float64'\n",
    "    schema[f's{s}_Peak'] = 'float64'\n",
    "    schema[f's{s}_Peak2Peak'] = 'float64'\n",
    "    schema[f's{s}_Crista'] = 'float64'\n",
    "for s in range(n_sensors):\n",
    "    for idx in range(len(yfs[0])):\n",
    "        schema[f's{s}_amp_{idx}'] = 'float64'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6fd4935-4144-4714-957c-9c346ad5856f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for split_key in ['val', 'test', 'train']:#[]\n",
    "    split_data_idxs = []\n",
    "    i, j = dataset_split_idxs[split_key]\n",
    "    for class_k, idxs in class_idxs.items():\n",
    "        split_data_idxs.extend(idxs[i:j])\n",
    "    df_split = pd.DataFrame(columns=schema.keys(), index=[i for i in range(len(split_data_idxs))]).astype(schema)\n",
    "    df_split.loc[:, ['Classe']] = classes_data[split_data_idxs]\n",
    "    for s in range(n_sensors):\n",
    "        for m, m_data in metrics_norm_map.items():\n",
    "            col_data = m_data[s][split_data_idxs]\n",
    "            col_label = f's{s}_{m}'\n",
    "            df_split.loc[:, [col_label]] = col_data\n",
    "\n",
    "        fft_vals = fft_ys[s][:][split_data_idxs]\n",
    "        for idx in range(len(fft_vals[0])):\n",
    "            col_label = f's{s}_amp_{idx}'\n",
    "            df_split.loc[:, [col_label]] = fft_vals[:,idx]\n",
    "    if save_dataset:\n",
    "        df_split.to_csv(f\"./dataset/processed/{split_key}_data.csv\", sep=',', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fiesc_env",
   "language": "python",
   "name": "fiesc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
